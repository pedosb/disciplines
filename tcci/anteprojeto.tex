\documentclass{ufpaanteprojeto}

\usepackage{graphicx}
\graphicspath{{figures/}}
\usepackage{subfig}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage[table]{xcolor}
\usepackage{url}
%separação silábica
\usepackage[T1]{fontenc}

\usepackage{setspace}

\hyphenation{LibreOffice re-co-nhe-ci-men-to fa-la-dos trans-cri-ção
cons-tru-ção se-me-lhan-te fe-de-ral ou-tras}

\newcommand{\comment}[1]{}

\begin{document}

\titulo{Utilizando Reconhecimento de Voz para Projetos de Acessibilidade}
\autor{Pedro dos Santos Batista}
\orientador{Aldebaro Barreto da Rocha Klautau Júnior}
\coorientador{Nelson Cruz Sampaio Neto}
\linhapesquisa{Reconhecimento automático de voz}

\fazercapa
\onehalfspacing

\section{Resumo}
A interface homem-máquina encontra-se cada vez mais amigável. O que
antigamente era feito através de cartões perfurados, hoje é possível
através do que conhecemos como teclados (um conjunto de teclas
pré-definidas), \emph{mouses}, incluindo a tecnologia \textit{touch
screen}, onde a tela mutável é sensível ao toque. Consideráveis
esforços vêm sendo reunidos para melhorar cada vez mais essa
comunicação, visando tornar realidade o que hoje é mostrado em
filmes de ficção científica, onde uma máquina é capaz de se
comunicar através da fala, pensar e agir como um ser humano.

Acredita-se que através do Reconhecimento Automático de Voz (RAV) e
da Síntese de Voz (TTS) seja possível conseguir uma interação mais
rápida e prática com a máquina. Várias são as aplicações que podem
usar a voz como interface, principalmente dentro das áreas de
acessibilidade e automação.

Hoje, existem no mercado alguns bons sintetizadores de voz com
suporte ao Português Brasileiro (PB), como é o caso do
\textit{eSpeak}~\cite{espeak}. No entanto, quando se fala em RAV,
não se tem a mesma disponibilidade. Os principais sistemas RAV
desenvolvidos com suporte ao PB foram o \textit{ViaVoice} da
IBM~\cite{viavoice} e o \textit{FreeSpeech 2000} da Nuance.
Entretanto, ambos foram descontinuados. Em contrapartida, quando se
fala em sistemas RAV para outras línguas, como a inglesa, existem
reconhecedores que possuem um excelente desempenho, entre
eles podemos citar o \textit{Dragon Naturally
Speaking}~\cite{dragonnuance} e o \textit{Windows Speech
Recognition}~\cite{windowsrecognition}.

Neste trabalho desenvolveremos um completo \textit{framework}
para desenvolvimento de aplicações que utilizam reconhecimento
de voz, este será um \textit{software} livre, isto significa que
programadores poderão usar RAV em suas aplicações sem nenhum
custo. Além disso, desenvolveremos aplicativos que possibilitarão
navegação Web utilizando apenas voz e ditado para a suíte
de escritório LibreOffice. Esses serão chamados
\textit{CorujaNavigator} e \textit{SpeechOO} respectivamente.

\section{Objetivos} \label{objetivos}
O estado da arte das tecnologias de voz são os modelos ocultos de
Markov (HMM)~\cite{Patricktcc,microsoftrecognizer}. Nesse contexto,
para se construir um sistema RAV, é preciso, primeiramente, de uma
grande base de dados (\emph{corpus}) para treinamento e teste do
sistema. Essas bases são compostas de arquivos de áudio e suas
respectivas transcrições ortográficas. De posse de uma base de dados
robusta, é possível construir os modelos acústico e de linguagem
utilizados no processo de decodificação.

Este trabalho tem como objetivo geral a disponibilização de recursos
para desenvolvimento de aplicações utilizando RAV em PB. Para isso
é necessário a criação de recursos como modelos acústicos
(AM) e de linguagem (LM). Distribuir esses recursos 
possibilitará que o programador se preocupe apenas
em desenvolver sua aplicação utilizando RAV, sem precisar
aprender detalhes da tecnologia. Porém disponibilizar
os modelos não é suficiente, pois os decodificadores
\textit{open-source}~\cite{Young06,Lee01-2,Walker04}
apresentam API pouco flexíveis quanto a linguagem de
programação além de exigirem um conhecimento
da tecnologia de RAV.

Dessa forma, visamos desenvolver também uma API compatível com a
interface Common Language Runtime (CLR)~\cite{clrsite}, essa permitirá
o desenvolvimento de aplicativos em linguagens de programação
do Microsoft .NET Framework~\cite{dotnetsite}. Dessa forma, 
o programador poderá se concentrar em desenvolver seu aplicativo,
sem se preocupar com detalhes de RAV, além de poder utilizar
recursos de várias linguagens de programação.

Uma vez disponibilizados esses recursos serão criadas duas aplicações
exemplo, o \textit{CorujaNavigator} e o \textit{SpeechOO},
a primeira tornará possível o acesso a Websites por deficientes
visuais e motores, isto é, o usuário utilizará apenas voz para controlar
a aplicação. Já o \textit{SpeechOO} utilizará os recursos desenvolvidos
para permitir ditado para a ferramenta de escritório
LibreOffice~\cite{libreofficesite}.

\section{Justificativa}
É observada uma grande oferta de \emph{softwares} com tecnologias de
voz para várias línguas, como a inglesa, japonesa e chinesa. Esses
reconhecedores e sintetizadores são conhecidos na área como
\emph{engines} de voz. Contudo, poucos são os esforços destinados a
língua portuguesa. A \textit{Microsoft} lançou recentemente seu
\emph{engine} de reconhecimento de voz para
PB~\cite{sampleenginemicrosoftpb}, porém existem restrições, como
código fonte proprietário, dificuldades na utilização, entre outras.

O projeto proposto almeja a implementação de recursos que
tornarão viável o desenvolvimento de aplicações utilizando
RAV em PB. Esse terá uma grande influência na área, pois por
ser um projeto \textit{open-source} possibilitará o uso de RAV
sem custos, difundindo-se livremente entre diversos
programadores e grupos de pesquisa.  Um dos interessados pelo
projeto é o aplicativo \textit{FFTranscriber}~\cite{fftranscriber}
cuja intenção é diminuir consideravelmente o tempo destinado
à perícia de transcrições de áudio forense.

\section{Relevância do estudo}
Não é observado hoje nenhum \textit{framework open-source}
para desenvolvimento de aplicações utilizando reconhecimento
de voz em PB. Dessa forma o presente trabalho é essencial
para o desenvolvimento dessa área no que diz respeito
ao Português Brasileiro.

Os recursos disponibilizados poderão ser utilizados para
o desenvolvimento de diversos aplicativos. Esses poderão
influenciar várias ações do nosso cotidiano, como tarefas de
automação, entretenimento e principalmente acessibilidade
que desenvolve um papel de desenvolvimento social.

\section{Problema da pesquisa a ser investigado}
Um dos principais problemas nessa tarefa será a transcrição
de áudio, pois esse é um trabalho cansativo e braçal.
Serão investigadas alternativas para tentar de automatizar ao máximo
essa tarefa, viabilizando a construção de \textit{corpus}
de áudio cada vez maiores.

A criação da API em CLR exigirá conhecimentos
de linguagem C, C++, C++/CLI e CLR, além do projeto Julius.
Esse será o maior desafio do projeto, visto que não existe
nenhuma garantia da possibilidade de utilizar o Julius em
um compilador compatível com C++/CLI.

No que diz respeito ao CorujaNavigator métodos de
aprendizagem serão aplicados, para que se torne possível
filtras de páginas Web textos de interesse a serem
sintetizados. Já para o SpeechOO será necessário
a investigação do desenvolvimento de
\textit{plugins} para o LibreOffice.

\section{Metas}
Ao final desse projeto os seguintes recursos deverão ser
disponibilizados:
\begin{itemize}
	\item Uma base de voz com aproximadamente 16 horas de áudio totalmente
		transcrita.
	\item \emph{Scripts} para coleta e formatação de
		textos extraídos automaticamente da Internet (\textit{crawling}),
		compondo um base de texto com mais de 1 milhão de
		sentenças.
	\item O aplicativo \textit{CorujaNavigator}: Um navegador Web \textit{hands-free}.
	\item O aplicativo \textit{SpeechOO}: Ditado no LibreOffice.
	\item O pacote Coruja: Um sistema de reconhecimento
		de voz para português brasileiro.
\end{itemize}

\section{Metodologia}
A tarefa de transcrição e edição dos arquivos de áudio será feita
utilizando o programa \textit{Transcriber}~\cite{Transcriber-SpeechComm2000}.
Esse \emph{software} possui uma interface que permite ao mesmo tempo
escutar e transcrever o áudio. Será desenvolvido um
\textit{script} para formatação automática das transcrições. Alguns
exemplos das operações realizadas que devem ser realizadas são:
remoção de marcações (``tags''); conversão de letras minúsculas
em maiúsculas; expansão de números e siglas; e correção de
palavras gramaticalmente incorretas.

Para a criação e avaliação dos modelos estatísticos faremos uso dos
\emph{softwares}: HTK~\cite{Young06}, Julius~\cite{Lee01-2} e
SRILM~\cite{stolcke02}. O HTK é uma ferramenta que permite manipular
HMMs; o Julius, é um decodificador \textit{open-source};
e o SRILM é um \textit{toolkit} para construção de modelos de linguagem.

Para a construção da API compatível com CLR será usada a linguagem
de programação C++/CLI, pois a partir dela será possível controlar
o Julius (linguagem C) e desenvolver métodos a serem utilizados em CLR.

\section{Resultados}
\label{resultados}

Nesse período de desenvolvimento de TCCI o projeto atingiu os seguintes objetivos:

\begin{itemize}
    \item Composição de uma base de voz com aproximadamente 16 horas de áudio totalmente
transcrita.
    \item Elaboração de \emph{scripts} para coleta e formatação de
textos extraídos automaticamente da Internet, compondo um base de
texto com cerca de 1 milhão de sentenças até o momento.
    \item Como prova de
conceito, foi desenvolvido o aplicativo PPTController,
que utiliza a LaPSAPI dentre outros recursos próprios aqui construídos.
\end{itemize}

No final obteve-se um bom desempenho utilizando gramáticas
controladas, fato que pode ser comprovado pela publicação deste
trabalho na \emph{International Conference on Computational Processing of the Portuguese Language} (PROPOR 2010), essa que é a conferência
internacional mais respeitada na área de Processamento de Linguagem
Natural para a língua portuguesa.

Os recursos descritos a seguir estão disponíveis juntamente com seus códigos
fonte na página do Projeto FalaBrasil~\cite{falabrasilsite}.

\subsection{LaPSStory}\label{sec:story}

A criação de um grande \emph{corpus} não é trivial, já que é preciso
a transcrição correta do áudio, contratação de locutores, enfim,
atividades que despendem muito tempo e recurso.

Visando contornar essa situação, buscou-se montar um \emph{corpus} a
partir de livros falados (\emph{audiobooks}), que são livros
narrados por locutores profissionais. Desse modo, podemos elaborar
facilmente as transcrições do texto. Uma dificuldade encontrada
nessa abordagem é o fato do texto ser lido por apenas um locutor,
característica que torna o \emph{corpus} menos eficiente, já que não
se consegue obter diferenças na fala, como os sotaques. Outro
problema em bases de livros falados é que os arquivos de áudio
possuem em média 70 minutos de duração. Com isso, esses arquivos
precisam ser editados em arquivos menores de 30 segundos, para que
possam ser usados no processo de construção do modelo acústico.

O trabalho então foi organizar 5 horas e 19 minutos de áudio e
compor sua transcrição ortográfica. Atividade feita manualmente.
Este \emph{corpus} foi utilizado para a construção dos modelos
probabilísticos usados em~\cite{sbrt09}.

\subsection{Corpus da Constituição}\label{sec:const}

Outra solução encontrada para a obtenção de \emph{corpus} de voz é
uma estratégia semelhante a dos livros falados (Seção~\ref{sec:story}) e consiste na
aquisição da legislação brasileira em áudio, mais especificamente a
Constituição Federal, fornecida pelo Senado Federal
em~\cite{legislacaoemaudio}.

Foram então convertidos em arquivos de 30 segundos cerca de 9 horas
de áudio da constituição e 1,5 hora do Código de Defesa do Consumidor.
Juntamente com o LaPSStory este \emph{corpus} foi
utilizado para a construção dos modelos probabilísticos usados
em~\cite{propor10}.

\subsection{LaPSNews}\label{sec:lapsnews}

Os modelos de linguagem são essenciais dentro de um sistema RAV, já
que assumem a função de caracterizar a língua. Esses modelos são
tipicamente construídos utilizando-se de modelos interpolados de
transcrições e textos de jornais, tais modelos são largamente
utilizados em tarefas de reconhecimento de voz em tempo real. O
corpus inicialmente utilizado foi o Corpus de Extratos de Textos
Eletrônicos NILC/Folha de S. Paulo (CETENFolha), um corpus com
aproximadamente 24 milhões de palavras, criado pelo projeto
Linguateca\footnote{www.linguateca.pt} com textos do jornal Folha de
S. Paulo e compilado pelo centro de pesquisa NILC/São Carlos,
Brasil.

O CETENFolha vem sendo complementado com textos recentes de outros
jornais. Isso vem sendo feito através de um processo totalmente
automatizado de formatação e coleta diária de jornais disponíveis na
Internet (``crawling''). Foi então construído o \emph{corpus} de
texto: \emph{LaPSNews}. Na sua primeira versão usada
em~\cite{sbrt09,propor10}, possuía cerca de 120 mil sentenças. Hoje,
contém mais de 1 milhão de sentenças.

\subsection{LaPSAPI}

A LaPSAPI permite o controle em tempo-real do \emph{engine} de
reconhecimento de voz, Julius, e da interface de áudio do sistema.
Como pode ser visto na Figura~\ref{fig:apimodel}, as aplicações
interagem com o reconhecedor Julius através da API.

\begin{figure}[!h]
   \centering
   \includegraphics[height=2.5in]{APImodel}
   \caption{Modelo de interação com a API.} \label{fig:apimodel}
\end{figure}

Visto que a API suporta objetos compatíveis com o modelo de
automação \emph{component object model} (COM), é possível acessar e
manipular (i.e. ajustar propriedades, invocar métodos) objetos de
automação compartilhados que são exportados por outras aplicações.
Do ponto de vista da programação, a API consiste de uma classe
principal denominada \textit{SREngine}. Essa classe expõe à
aplicação um conjunto de métodos e eventos descritos na
Tabela~\ref{tab:apimethods}.

\begin{table}[!h]
\begin{center}
\begin{tabular}{ l | l}
  \toprule
  \textbf{Métodos/Eventos} & \textbf{Descrição Básica} \\ \midrule
  SREngine & Método para carregar e inicializar o reconhecedor \\ \midrule
  loadGrammar & Método para carregar gramática SAPI XML\\ \midrule
  addGrammar & Método para carregar gramática nativa do Julius\\ \midrule
  startRecognition & Método para iniciar o reconhecimento \\ \midrule
  stopRecognition & Método para pausar/parar o reconhecimento \\ \midrule
  OnRecognition & Evento chamado quando alguma sentença é reconhecida \\ \midrule
  OnSpeechReady & Evento chamado quando o reconhecimento é ativado \\
  \bottomrule
\end{tabular}
\end{center}
\caption{Principais métodos e eventos da API.}
\label{tab:apimethods}
\end{table}

A classe \textit{SREngine} permite que a aplicação
controle aspectos do reconhecedor Julius. Essa classe possibilita
que a aplicação carregue os modelos acústico e de linguagem a serem
utilizados, inicie e pare o reconhecimento, e receba eventos e
resultados provenientes do \textit{engine} de reconhecimento.

Uma aplicação baseada em voz precisa criar, carregar e ativar uma
gramática, que essencialmente indica o método de reconhecimento
empregado, ou seja, ditado ou livre de contexto. A gramática para
ditado é implementada via modelo de linguagem, que define um extenso
conjunto de palavras. Por sua vez, essas palavras podem ser
pronunciadas de uma forma relativamente irrestrita. Já a gramática
livre de contexto age como um modelo de linguagem. Ela provê ao
reconhecedor regras que definem o que pode ser dito.

Através do método \emph{loadGrammar} é possível carregar uma
gramática livre de contexto especificada no formato Microsoft Speech
API (SAPI) XML. Para tornar isso possível, um conversor gramatical
foi desenvolvido e integrado ao método \emph{loadGrammar}. Essa
ferramenta permite que o sistema converta automaticamente uma
gramática de reconhecimento especificada no padrão SAPI \emph{Text
Grammar Format}~\cite{sapixml} para o formato suportado pelo
Julius\footnote{O decodificador Julius suporta tanto modelos de
linguagem, como gramáticas livre de contexto.}. O procedimento de
conversão usa as regras gramaticais SAPI para encontrar as conexões
permitidas entre as palavras, usando o nome das categorias como nós
terminais. Isso também define as palavras candidatas em cada
categoria, juntamente com as suas respectivas pronúncias.

É importante salientar que o conversor ainda não suporta regras
gramaticais recursivas, facilidade suportada pelo Julius. Para esse
tipo de funcionalidade deve-se carregar a gramática nativa do Julius
através do método \emph{addGrammar}.
A especificação para esse tipo de gramática pode ser encontrada em~\cite{juliusgrammar}.

O método \textit{startRecognition}, responsável por iniciar o
processo de reconhecimento, basicamente ativa as regras gramaticais
e abre o \textit{stream} de áudio. Similarmente, o método
\textit{stopRecognition} desativa as regras e fecha o
\textit{stream} de áudio.

Adicionalmente aos métodos, alguns eventos também foram
implementados. O evento \textit{OnSpeechReady} sinaliza que o
\textit{engine} está ativado para reconhecimento. Em outras
palavras, ele surge toda vez que o método \textit{startRecognition}
é invocado. Já o evento \textit{OnRecognition} acontece sempre que
o resultado do reconhecimento encontra-se disponível, juntamente com
o seu nível de confiança.

A medida de confiança do que foi reconhecido pelo \textit{engine} é
essencial para aplicações reais, dado que sempre ocorrerá erros de
reconhecimento e, portanto, os resultados podem ser aceitos ou
rejeitados. A sequência de palavras reconhecidas e o seu nível de
confiança são passados da API para a aplicação através da classe
\textit{RecoResult}.

Esta API juntamente com os modelos produzidos a partir dos corpus citados
nas seções ~\ref{sec:story},~\ref{sec:const} e~\ref{sec:lapsnews} formam
o pacote Coruja que foi publicado como: \textit{An Open-Source Speech
Recognizer for Brazilian Portuguese with a Windows Programming
Interface}~\cite{propor10}.

\subsection{PPTController}

Para entender o funcionamento da SAPI, foi desenvolvido um
\emph{software} onde é possível controlar uma apresentação de
\textit{slides} do programa \textit{Microsoft Office Power Point
2007} usando apenas comandos de voz. Foi utilizado o reconhecedor de
voz para PB da \emph{Microsoft}: \textit{Speech Recognition Sample
Engine for Portuguese (Brazil)}.

%%%%%%%%%%%%%%Colocar uma figura com a tela principal do aplicativo
\begin{figure}[!h]
   \centering
   \includegraphics[height=2.5in]{ppt_controller}
   \caption{Tela inicial do aplicativo PPTController} \label{fig:pptcontroller}
\end{figure}

A Figura~\ref{fig:pptcontroller} mostra a tela principal do
aplicativo. Seu funcionamento é bastante simples. Inicialmente é
necessário abrir uma apresentação de \emph{slides}, sendo então
possível habilitar o reconhecedor para receber os comandos de voz. O
comando inicial deve ser \textbf{mostrar} para iniciar a
apresentação. Em seguida pode-se comandar a apresentação através de
comandos específicos. São eles:

\begin{itemize}
 \item \textbf{Mostrar:} primeiro comando que deve ser enviado, pois abre o \textit{slide show}.
 \item \textbf{Próximo ou Avançar:} ir para o próximo \textit{slide} da apresentação.
 \item \textbf{Anterior ou Voltar:} voltar para o \textit{slide} anterior na apresentação.
 \item \textbf{Primeiro:} ir imediatamente para o primeiro \textit{slide} da apresentação.
 \item \textbf{Último:} ir imediatamente para o último \textit{slide} da apresentação.
 \item \textbf{Fechar:} fechar a apresentação e voltar para a tela principal do aplicativo.
\end{itemize}

Para comprovar também o funcionamento da LaPSAPI e dos modelos
desenvolvidos, o aplicativo PPTController foi migrado para utilização do Coruja
e obtivemos resultado satisfatório.
\newpage

\section{Cronograma de execução}
\newcommand{\m}{\cellcolor{black}}
\begin{table}[htp]
	\centering
	\begin{tabular}{|p{9cm}|c|c|c|c|c|c|}
		\hline
		\multirow{2}{*}{\textbf{Atividades}} & \multicolumn{6}{|c|}{\textbf{Meses de execução TCC I}} \\\cline{2-7}
		& 01 & 02 & 03 & 04 & 05 & 06 \\\hline
		Transcrição de áudio & \m & \m & \m & \m & \m & \m \\\hline
		Estudo de linguagens CLR & \m & \m & \m & \m & & \\\hline
		Estudo do código do Julius & & & \m & \m & & \\\hline
		Utilização do código do Julius em compilador compatível com CLR & & & & \m & \m & \m \\\hline
		Projeto de API para fácil utilização de RAV & & & & & \m & \m \\\hline
		Criação de \textit{scripts} para crawling & & & & & \m & \m \\\hline
	\end{tabular}
	\caption{Cronograma de execução do TCC I}
	\label{tab:cronogramatcci}
\end{table}

\begin{table}[htp]
	\centering
	\begin{tabular}{|p{9cm}|c|c|c|c|c|c|}
		\hline
		\multirow{2}{*}{\textbf{Atividades}} & \multicolumn{6}{|c|}{\textbf{Meses de execução TCC II}} \\\cline{2-7}
		& 01 & 02 & 03 & 04 & 05 & 06 \\\hline
		Implementação da API projetada & \m & \m & \m & & & \\\hline
		Desenvolvimento do CorujaNavigator & & & \m & \m & \m & \\\hline
		Estudo de desenvolvimento de \textit{plugins} para o LibreOffice & & \m & \m & & & \\\hline
		Desenvolvimento do SpeechOO & & & & \m & \m & \m \\\hline
		Desenvolvimento de manuais e documentação & & & \m & \m & \m & \m \\\hline
	\end{tabular}
	\caption{Cronograma de execução do TCC II}
	\label{tab:cronogramatccii}
\end{table}

\bibliographystyle{plain}
\bibliography{bibliografia,bib}


\comment{
\newpage
\begin{center}
	\textbf{
	\huge
	ANEXO 2}
\end{center}

\section{Formulário de Avaliação de Trabalho de Conclusão de Curso I}

\subsection{Considerações gerais sobre o trabalho}

\subsection{Quanto à revisão bibliográfica realizada}
\begin{itemize}
	\item Atualidade e pertinência das referências
	\item Levantamento do estado-da-arte da área alvo
	\item Abrangência e profundidade da revisão bibliográfica.
\end{itemize}

\subsection{Quanto à constituição e confecção do trabalho}
\begin{itemize}
	\item Seqüência lógica da estruturação do trabalho
\end{itemize}

\subsection{Quanto à contribuição do trabalho}
\begin{itemize}
	\item Clareza nos objetivos do trabalho
	\item Obtenção dos resultados esperados
	\item Relevância da contribuição
	\item Pertinência da implementação
	\item Fidelidade da solução à idéia proposta
\end{itemize}

\subsection{Quanto ao desempenho do aluno}

\subsection{Avaliação final conclusiva}
\begin{itemize}
	\item a) qual a nota e conceito do aluno na disciplina TCC I?
	\item b) solicita que o aluno seja matriculado em TCC II sob sua orientação, para
concluir o trabalho avaliado nesse documento? (SIM / NÃO / caso haja
mudanças, informar em separado)
\end{itemize}
}

\end{document}
